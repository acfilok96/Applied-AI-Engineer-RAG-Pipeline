# Colab Notebook - Base Code

## `Notebook [.ipynb]` Folder

```
Notebook [.ipynb]/
      |
      â”œâ”€â”€ 12587973.pdf
      â”œâ”€â”€ RAG Pipeline - Process 1 [Without ReRanker].ipynb
      â”œâ”€â”€ RAG Pipeline - Process 1.ipynb
      â”œâ”€â”€ RAG Pipeline - Process 2 [Without ReRanker].ipynb
      â”œâ”€â”€ RAG Pipeline - Process 2.ipynb
      â””â”€â”€ README.md
```

In these notebook files, [12587973.pdf](https://github.com/DIPANKARPOREY/Applied-AI-Engineer-RAG-Pipeline/blob/main/Base%20Code%20(Notebook%20Files)/12587973.pdf) document have been used and check out the results for that.

## Set up API Keys ðŸ”—

Change the required API key inside the function by generating key accordingly

- **LlamaCloud API key:**  [LlamaCloud](https://cloud.llamaindex.ai/api-key)

- **HuggingFace API key:**  [HuggingFace](https://huggingface.co/settings/tokens)
 
- **Groq API key:**  [groqcloud](https://console.groq.com/keys) 


## About Processes

#### **[RAG Pipeline - Process 1.ipynb](https://github.com/DIPANKARPOREY/Applied-AI-Engineer-RAG-Pipeline/blob/main/Base%20Code%20(Notebook%20Files)/RAG%20Pipeline%20-%20Process%201.ipynb)** : 
In this process, `without` `UnstructuredMarkdownLoader`, a tool within the LangChain ecosystem designed to facilitate the loading of Markdown documents into a structured format suitable for downstream processing and `With` `FlashRank`, a Python library to add re-ranking to your existing search & retrieval pipelines. It is based on SoTA cross-encoders, with gratitude to all the model owners that have been used.


#### **[RAG Pipeline - Process 1 [Without ReRanker].ipynb](https://github.com/DIPANKARPOREY/Applied-AI-Engineer-RAG-Pipeline/blob/main/Base%20Code%20(Notebook%20Files)/RAG%20Pipeline%20-%20Process%201%20%5BWithout%20ReRanker%5D.ipynb)** : 
`Without` `UnstructuredMarkdownLoader` a tool  designed to facilitate the loading of Markdown documents into a structured format suitable for downstream processing and `Without` `FlashRank`, a Python library to add re-ranking to your existing search & retrieval pipelines. It is based on SoTA cross-encoders, with gratitude to all the model owners that have been used.


#### **[RAG Pipeline - Process 2.ipynb](https://github.com/DIPANKARPOREY/Applied-AI-Engineer-RAG-Pipeline/blob/main/Base%20Code%20(Notebook%20Files)/RAG%20Pipeline%20-%20Process%202.ipynb)** :  
In this process, `with` `UnstructuredMarkdownLoader`, a tool within the LangChain ecosystem designed to facilitate the loading of Markdown documents into a structured format suitable for downstream processing and `With` `FlashRank`, a Python library to add re-ranking to your existing search & retrieval pipelines. It is based on SoTA cross-encoders, with gratitude to all the model owners that have been used.


#### **[RAG Pipeline - Process 2 [Without ReRanker].ipynb](https://github.com/DIPANKARPOREY/Applied-AI-Engineer-RAG-Pipeline/blob/main/Base%20Code%20(Notebook%20Files)/RAG%20Pipeline%20-%20Process%202%20%5BWithout%20ReRanker%5D.ipynb)** : 
`With` `UnstructuredMarkdownLoader` a tool  designed to facilitate the loading of Markdown documents into a structured format suitable for downstream processing and `Without` `FlashRank`, a Python library to add re-ranking to your existing search & retrieval pipelines. It is based on SoTA cross-encoders, with gratitude to all the model owners that have been used.
